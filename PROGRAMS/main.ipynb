{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.dataloader import *\n",
    "from utils.coordinate_calibration import PointCloudRegistration\n",
    "from utils.meshgrid import Meshgrid\n",
    "from utils.icp import IterativeClosestPoint, Matching\n",
    "from utils.deformable_icp import DeformableICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '../OUTPUT'\n",
    "DATA_DIR = './pa345_data'\n",
    "\n",
    "RIGID_BODY_DATA_A = f'{DATA_DIR}/Problem5-BodyA.txt'\n",
    "RIGID_BODY_DATA_B = f'{DATA_DIR}/Problem5-BodyB.txt'\n",
    "\n",
    "SURFACE_DATA = f'{DATA_DIR}/Problem5MeshFile.sur'\n",
    "\n",
    "SAMPLE_ID = 'F'\n",
    "SAMPLE_DATA = f'./pa345_data/PA5-{SAMPLE_ID}-Debug-SampleReadingsTest.txt'\n",
    "# SAMPLE_DATA = f'./pa345_data/PA5-{SAMPLE_ID}-Unknown-SampleReadingsTest.txt'\n",
    "\n",
    "# Load data files\n",
    "rigidbody_dl_A = RigidBodyDataloader.read_file(RIGID_BODY_DATA_A)\n",
    "rigidbody_dl_B = RigidBodyDataloader.read_file(RIGID_BODY_DATA_B)\n",
    "\n",
    "surface_dl = Surfaceloader.read_file(SURFACE_DATA)\n",
    "sample_dl = SampleReadingsDataloader.read_file(SAMPLE_DATA, delimiter=',', N_A=rigidbody_dl_A.N_markers, N_B=rigidbody_dl_B.N_markers)\n",
    "\n",
    "modes_dl = AtlasModesDataloader.read_file(f'{DATA_DIR}/Problem5Modes.txt')\n",
    "print(modes_dl.modes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get F<sub>A, k</sub> and F<sub>B, k</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigidbody_dl_A_markers = rigidbody_dl_A.markers.reshape(1, -1, 3) # markers of body A in body A coordinates\n",
    "\n",
    "sample_dl_A = sample_dl.body_A # samples of body A markers in tracker coordinates\n",
    "num_samples = sample_dl.N_samps\n",
    "\n",
    "# perform registration for each frame\n",
    "reg = PointCloudRegistration(verbose=False)\n",
    "F_A = []\n",
    "for i in range(num_samples):\n",
    "    sample_dl_A_i = sample_dl_A[i].reshape(1, -1, 3)\n",
    "    F_A_i, err = reg.register(rigidbody_dl_A_markers, sample_dl_A_i)\n",
    "    F_A.append(F_A_i)\n",
    "\n",
    "F_A = np.array(F_A)\n",
    "\n",
    "ridigbody_dl_B_markers = rigidbody_dl_B.markers.reshape(1, -1, 3) # markers of body B in body B coordinates\n",
    "sample_dl_B = sample_dl.body_B # samples of body B markers in tracker coordinates\n",
    "\n",
    "# perform registration for each frame\n",
    "F_B = []\n",
    "for i in range(num_samples):\n",
    "    sample_dl_B_i = sample_dl_B[i].reshape(1, -1, 3)\n",
    "\n",
    "    F_B_i, err = reg.register(ridigbody_dl_B_markers, sample_dl_B_i)\n",
    "    F_B.append(F_B_i)\n",
    "\n",
    "F_B = np.array(F_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get d<sub>k</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tip = rigidbody_dl_A.tip\n",
    "A_tip = np.append(A_tip, 1) # add 1 for homogenous coordinates\n",
    "d_k = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    F_A_i = F_A[i] # get F_A for frame i\n",
    "    F_B_i_inv = np.linalg.inv(F_B[i]) # get F_B inverse for frame i\n",
    "\n",
    "    d_k.append(F_B_i_inv @ F_A_i @ A_tip) # d_k = F_B^-1 * F_A * A_tip\n",
    "\n",
    "d_k = np.array(d_k)[:,:3]\n",
    "print(d_k.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute s<sub>k</sub>, c<sub>k</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "csv_elapsed_time_file = f'{OUTPUT_DIR}/pa5-ElapsedTime.csv'\n",
    "with open(csv_elapsed_time_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Iteration', 'Elapsed Time (s)'])\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Initialize ICP helper class \n",
    "    deform_icp = DeformableICP()\n",
    "\n",
    "    # Initialize meshgrid of Triangles\n",
    "    mesh = Meshgrid(surface_dl.vertices, surface_dl.triangles)\n",
    "\n",
    "    best_pt_cloud, closest_pt, dist, F_best, λ_best = deform_icp(d_k, mesh, modes_dl.modes)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    with open(csv_elapsed_time_file, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([i, elapsed_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(λ_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f'{OUTPUT_DIR}/pa5-{SAMPLE_ID}-Output.txt'\n",
    "with open(output_file, 'w') as file:\n",
    "    file.write(f\"{num_samples}, {output_file}\\n\")\n",
    "    file.write(\" \".join(map(lambda x: f\"{x:.4f}\", λ_best[1:])) + \"\\n\")\n",
    "    for sample in range(num_samples):\n",
    "        file.write(f\"{best_pt_cloud[sample][0]:.2f} {best_pt_cloud[sample][1]:.2f} {best_pt_cloud[sample][2]:.2f} \")\n",
    "        file.write(f\"{closest_pt[sample][0]:.2f} {closest_pt[sample][1]:.2f} {closest_pt[sample][2]:.2f}\")\n",
    "        file.write(f\" {dist[sample]:.2f}\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(f\"Output written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare predicted with debug output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_output_file = f'{OUTPUT_DIR}/pa5-ErrorMetrics.csv'\n",
    "with open(csv_output_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Sample', \"Error_weights\", 'Error_s_k', 'Error_c_k', 'Error_norm'])\n",
    "\n",
    "for sample_id in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "    SAMPLE_ID = sample_id\n",
    "\n",
    "    pred_file = f'{OUTPUT_DIR}/pa5-{SAMPLE_ID}-Output.txt'\n",
    "    gt_file = f'{DATA_DIR}/PA5-{SAMPLE_ID}-Debug-Answer.txt'\n",
    "\n",
    "    dl1 = OutputDataloader.read_file(pred_file)\n",
    "    dl2 = OutputDataloader.read_file(gt_file)\n",
    "\n",
    "    weights1 = dl1.weights\n",
    "    weights2 = dl2.weights\n",
    "\n",
    "    raw_data1 = dl1.raw_data\n",
    "    raw_data2 = dl2.raw_data\n",
    "\n",
    "    error_weights = np.mean(np.abs(weights1 - weights2))\n",
    "\n",
    "    # get the mean absolute error for d_x\n",
    "    error_s_x = np.mean(np.abs(raw_data1[:, 0] - raw_data2[:, 0]))\n",
    "    # get the mean absolute error for d_y\n",
    "    error_s_y = np.mean(np.abs(raw_data1[:, 1] - raw_data2[:, 1]))\n",
    "    # get the mean absolute error for d_z\n",
    "    error_s_z = np.mean(np.abs(raw_data1[:, 2] - raw_data2[:, 2]))\n",
    "    error_s_k = (error_s_x, error_s_y, error_s_z)\n",
    "    error_s_k_avg = np.mean(error_s_k)\n",
    "\n",
    "    # get the mean absolute error for c_x\n",
    "    error_c_x = np.mean(np.abs(raw_data1[:, 3] - raw_data2[:, 3]))\n",
    "    # get the mean absolute error for c_y\n",
    "    error_c_y = np.mean(np.abs(raw_data1[:, 4] - raw_data2[:, 4]))\n",
    "    # get the mean absolute error for c_z\n",
    "    error_c_z = np.mean(np.abs(raw_data1[:, 5] - raw_data2[:, 5]))\n",
    "    error_c_k = (error_c_x, error_c_y, error_c_z)\n",
    "    error_c_k_avg = np.mean(error_c_k)\n",
    "\n",
    "    # get the mean absolute error for ||d_k-c_k||\n",
    "    error_norm = np.mean(np.abs(raw_data1[:, 6] - raw_data2[:, 6]))\n",
    "    with open(csv_output_file, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([SAMPLE_ID, round(error_weights, 4), round(error_s_k_avg, 4), round(error_c_k_avg, 4), round(error_norm, 4)])\n",
    "\n",
    "print(f\"Error metrics written to {csv_output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown output summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_output_file = f'{OUTPUT_DIR}/pa5-Unknown-Summary.csv'\n",
    "with open(csv_output_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Sample', \"Average weight\", 'Average s_k', 'Average c_k', 'Average norm'])\n",
    "\n",
    "for sample_id in ['G', 'H', 'J', 'K']:\n",
    "    SAMPLE_ID = sample_id\n",
    "\n",
    "    pred_file = f'{OUTPUT_DIR}/pa5-{SAMPLE_ID}-Output.txt'\n",
    "\n",
    "    dl1 = OutputDataloader.read_file(pred_file)\n",
    "\n",
    "    weights1 = dl1.weights\n",
    "\n",
    "    raw_data1 = dl1.raw_data\n",
    "\n",
    "    error_weights = np.mean(np.abs(weights1))\n",
    "\n",
    "    # get the mean absolute error for d_x\n",
    "    error_s_x = np.mean(np.abs(raw_data1[:, 0]))\n",
    "    # get the mean absolute error for d_y\n",
    "    error_s_y = np.mean(np.abs(raw_data1[:, 1]))\n",
    "    # get the mean absolute error for d_z\n",
    "    error_s_z = np.mean(np.abs(raw_data1[:, 2]))\n",
    "    error_s_k = (error_s_x, error_s_y, error_s_z)\n",
    "    error_s_k_avg = np.mean(error_s_k)\n",
    "\n",
    "    # get the mean absolute error for c_x\n",
    "    error_c_x = np.mean(np.abs(raw_data1[:, 3]))\n",
    "    # get the mean absolute error for c_y\n",
    "    error_c_y = np.mean(np.abs(raw_data1[:, 4]))\n",
    "    # get the mean absolute error for c_z\n",
    "    error_c_z = np.mean(np.abs(raw_data1[:, 5]))\n",
    "    error_c_k = (error_c_x, error_c_y, error_c_z)\n",
    "    error_c_k_avg = np.mean(error_c_k)\n",
    "\n",
    "    # get the mean absolute error for ||d_k-c_k||\n",
    "    error_norm = np.mean(np.abs(np.subtract(error_s_k, error_c_k)))\n",
    "    with open(csv_output_file, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([SAMPLE_ID, round(error_weights, 4), round(error_s_k_avg, 4), round(error_c_k_avg, 4), round(error_norm, 4)])\n",
    "\n",
    "print(f\"Error metrics written to {csv_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pa4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
