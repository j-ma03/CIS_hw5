{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.dataloader import *\n",
    "from utils.coordinate_calibration import PointCloudRegistration\n",
    "from utils.meshgrid import Meshgrid\n",
    "from utils.icp import IterativeClosestPoint, Matching\n",
    "import os\n",
    "from test import FileOutputMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '../OUTPUT'\n",
    "DATA_DIR = './pa345_data'\n",
    "\n",
    "RIGID_BODY_DATA_A = f'{DATA_DIR}/Problem4-BodyA.txt'\n",
    "RIGID_BODY_DATA_B = f'{DATA_DIR}/Problem4-BodyB.txt'\n",
    "\n",
    "SURFACE_DATA = f'{DATA_DIR}/Problem4MeshFile.sur'\n",
    "\n",
    "SAMPLE_ID = 'A'\n",
    "SAMPLE_DATA = f'./pa345_data/PA4-{SAMPLE_ID}-Debug-SampleReadingsTest.txt'\n",
    "# SAMPLE_DATA = f'./pa345_data/PA4-{SAMPLE_ID}-Unknown-SampleReadingsTest.txt'\n",
    "\n",
    "# Load data files\n",
    "rigidbody_dl_A = RigidBodyDataloader.read_file(RIGID_BODY_DATA_A)\n",
    "rigidbody_dl_B = RigidBodyDataloader.read_file(RIGID_BODY_DATA_B)\n",
    "\n",
    "surface_dl = Surfaceloader.read_file(SURFACE_DATA)\n",
    "sample_dl = SampleReadingsDataloader.read_file(SAMPLE_DATA, delimiter=',', N_A=rigidbody_dl_A.N_markers, N_B=rigidbody_dl_B.N_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get F<sub>A, k</sub> and F<sub>B, k</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigidbody_dl_A_markers = rigidbody_dl_A.markers.reshape(1, -1, 3) # markers of body A in body A coordinates\n",
    "\n",
    "sample_dl_A = sample_dl.body_A # samples of body A markers in tracker coordinates\n",
    "num_samples = sample_dl.N_samps\n",
    "\n",
    "# perform registration for each frame\n",
    "reg = PointCloudRegistration(verbose=False)\n",
    "F_A = []\n",
    "for i in range(num_samples):\n",
    "    sample_dl_A_i = sample_dl_A[i].reshape(1, -1, 3)\n",
    "    F_A_i, err = reg.register(rigidbody_dl_A_markers, sample_dl_A_i)\n",
    "    F_A.append(F_A_i)\n",
    "\n",
    "F_A = np.array(F_A)\n",
    "\n",
    "ridigbody_dl_B_markers = rigidbody_dl_B.markers.reshape(1, -1, 3) # markers of body B in body B coordinates\n",
    "sample_dl_B = sample_dl.body_B # samples of body B markers in tracker coordinates\n",
    "\n",
    "# perform registration for each frame\n",
    "F_B = []\n",
    "for i in range(num_samples):\n",
    "    sample_dl_B_i = sample_dl_B[i].reshape(1, -1, 3)\n",
    "\n",
    "    F_B_i, err = reg.register(ridigbody_dl_B_markers, sample_dl_B_i)\n",
    "    F_B.append(F_B_i)\n",
    "\n",
    "F_B = np.array(F_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get d<sub>k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 3)\n"
     ]
    }
   ],
   "source": [
    "A_tip = rigidbody_dl_A.tip\n",
    "A_tip = np.append(A_tip, 1) # add 1 for homogenous coordinates\n",
    "d_k = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    F_A_i = F_A[i] # get F_A for frame i\n",
    "    F_B_i_inv = np.linalg.inv(F_B[i]) # get F_B inverse for frame i\n",
    "\n",
    "    d_k.append(F_B_i_inv @ F_A_i @ A_tip) # d_k = F_B^-1 * F_A * A_tip\n",
    "\n",
    "d_k = np.array(d_k)[:,:3]\n",
    "print(d_k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04<01:15,  2.49it/s, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 1 with Matching.VECTORIZED_LINEAR: 5.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04<01:07,  2.80it/s, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 2 with Matching.VECTORIZED_LINEAR: 4.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04<01:03,  2.97it/s, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 3 with Matching.VECTORIZED_LINEAR: 4.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04<01:03,  2.98it/s, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 4 with Matching.VECTORIZED_LINEAR: 4.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04<01:04,  2.93it/s, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 5 with Matching.VECTORIZED_LINEAR: 4.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:12<03:08,  1.00s/it, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 1 with Matching.VECTORIZED_OCTREE: 12.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:11<03:06,  1.01it/s, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 2 with Matching.VECTORIZED_OCTREE: 12.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:13<03:26,  1.10s/it, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 3 with Matching.VECTORIZED_OCTREE: 14.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:12<03:13,  1.03s/it, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 4 with Matching.VECTORIZED_OCTREE: 13.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:11<03:03,  1.02it/s, match=0.00194, prev_match_ratio=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for iteration 5 with Matching.VECTORIZED_OCTREE: 12.62s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "\n",
    "elapsed_time_csv = f'{OUTPUT_DIR}/elapsed_times_vectorized.csv'\n",
    "with open(elapsed_time_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Match Mode', 'Iteration', 'Elapsed Time (s)'])\n",
    "\n",
    "    for MATCH_MODE in [Matching.VECTORIZED_LINEAR, Matching.VECTORIZED_OCTREE]:\n",
    "        elapsed_times = []\n",
    "        for i in range(5):\n",
    "            matching_algo = MATCH_MODE\n",
    "\n",
    "            start_time = time.time()\n",
    "            # Initialize ICP helper class \n",
    "            icp = IterativeClosestPoint(match_mode=matching_algo)\n",
    "\n",
    "            # Initialize meshgrid of Triangles\n",
    "            mesh = Meshgrid(surface_dl.vertices, surface_dl.triangles)\n",
    "\n",
    "            best_cloud, closest_pt, dist, F = icp(d_k, mesh)\n",
    "            end_time = time.time()\n",
    "\n",
    "            elapsed_time = end_time - start_time\n",
    "            elapsed_times.append(elapsed_time)\n",
    "\n",
    "            print(f'Elapsed time for iteration {i+1} with {MATCH_MODE}: {elapsed_time:.2f}s')\n",
    "        \n",
    "        i = 0\n",
    "        for elapsed_time in elapsed_times:\n",
    "            writer.writerow([MATCH_MODE.name, i + 1, round(elapsed_time, 2)])\n",
    "            i+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "\n",
    "elapsed_time_csv = f'{OUTPUT_DIR}/elapsed_times_simple.csv'\n",
    "with open(elapsed_time_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Match Mode', 'Iteration', 'Elapsed Time (s)'])\n",
    "\n",
    "    for MATCH_MODE in [Matching.SIMPLE_LINEAR, Matching.SIMPLE_OCTREE]:\n",
    "        elapsed_times = []\n",
    "        for i in range(1):\n",
    "            matching_algo = MATCH_MODE\n",
    "\n",
    "            start_time = time.time()\n",
    "            # Initialize ICP helper class \n",
    "            icp = IterativeClosestPoint(match_mode=matching_algo)\n",
    "\n",
    "            # Initialize meshgrid of Triangles\n",
    "            mesh = Meshgrid(surface_dl.vertices, surface_dl.triangles)\n",
    "\n",
    "            best_cloud, closest_pt, dist, F = icp(d_k, mesh)\n",
    "            end_time = time.time()\n",
    "\n",
    "            elapsed_time = end_time - start_time\n",
    "            elapsed_times.append(elapsed_time)\n",
    "\n",
    "            print(f'Elapsed time for iteration {i+1} with {MATCH_MODE}: {elapsed_time:.2f}s')\n",
    "        \n",
    "        i = 0\n",
    "        for elapsed_time in elapsed_times:\n",
    "            writer.writerow([MATCH_MODE.name, i + 1, round(elapsed_time, 2)])\n",
    "            i+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to ../OUTPUT/pa3-J-Output.txt\n"
     ]
    }
   ],
   "source": [
    "output_file = f'{OUTPUT_DIR}/pa3-{SAMPLE_ID}-Output.txt'\n",
    "with open(output_file, 'w') as file:\n",
    "    file.write(f\"{num_samples}, {output_file}\\n\")\n",
    "    for sample in range(num_samples):\n",
    "        file.write(f\"{best_cloud[sample][0]:.2f} {best_cloud[sample][1]:.2f} {best_cloud[sample][2]:.2f} \")\n",
    "        file.write(f\"{closest_pt[sample][0]:.2f} {closest_pt[sample][1]:.2f} {closest_pt[sample][2]:.2f}\")\n",
    "        file.write(f\" {dist[sample]:.2f}\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(f\"Output written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare experimental and expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analysis written to ../OUTPUT/error_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "output_csv = f'{OUTPUT_DIR}/error_analysis.csv'\n",
    "\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Dataset', 'Pointer tip MAE', 'Closest point MAE', 'Error norm']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for SAMPLE_ID in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "        pred_file = f'{OUTPUT_DIR}/pa4-{SAMPLE_ID}-Output.txt'\n",
    "        gt_file = f'{DATA_DIR}/PA4-{SAMPLE_ID}-Debug-Output.txt'\n",
    "\n",
    "        if os.path.exists(pred_file) and os.path.exists(gt_file):\n",
    "            matcher = FileOutputMatcher()\n",
    "\n",
    "            error_s_k, error_c_k, error_norm = matcher(pred_file, gt_file)\n",
    "            avg_error_s_k = round(np.mean(error_s_k), 3)\n",
    "            avg_error_c_k = round(np.mean(error_c_k), 3)\n",
    "            error_norm = round(error_norm, 3)\n",
    "\n",
    "            writer.writerow({\n",
    "                'Dataset': f'Debug {SAMPLE_ID}',\n",
    "                'Pointer tip MAE': avg_error_s_k,\n",
    "                'Closest point MAE': avg_error_c_k,\n",
    "                'Error norm': error_norm\n",
    "            })\n",
    "        else:\n",
    "            print(f'No prediction or ground-truth file found for sample {SAMPLE_ID}. Skipping operation.')\n",
    "\n",
    "print(f\"Error analysis written to {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unknown g, h, j summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SAMPLE_ID in ['G', 'H', 'J']:\n",
    "    input = f'{OUTPUT_DIR}/pa4-{SAMPLE_ID}-Output.txt'\n",
    "    output_csv = f'{OUTPUT_DIR}/{SAMPLE_ID}-summary.csv'\n",
    "\n",
    "    with open(input, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip the first line\n",
    "        s_x = []\n",
    "        s_y = []\n",
    "        s_z = []\n",
    "        c_x = []\n",
    "        c_y = []\n",
    "        c_z = []\n",
    "        norm = []\n",
    "        for row in reader:\n",
    "            row = list(map(float, row[0].split()))\n",
    "            s_x.append(row[0])\n",
    "            s_y.append(row[1])\n",
    "            s_z.append(row[2])\n",
    "            c_x.append(row[3])\n",
    "            c_y.append(row[4])\n",
    "            c_z.append(row[5])\n",
    "            norm.append(row[6])\n",
    "\n",
    "    s_x_avg = np.mean(s_x)\n",
    "    s_y_avg = np.mean(s_y)\n",
    "    s_z_avg = np.mean(s_z)\n",
    "    c_x_avg = np.mean(c_x)\n",
    "    c_y_avg = np.mean(c_y)\n",
    "    c_z_avg = np.mean(c_z)\n",
    "    s_xyz_avg = (s_x_avg + s_y_avg + s_z_avg) / 3\n",
    "    c_xyz_avg = (c_x_avg + c_y_avg + c_z_avg) / 3\n",
    "    norm_avg = np.mean(norm)\n",
    "\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Pointer tip average', 'Closest point average', 'Error norm average']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        writer.writerow({\n",
    "            'Pointer tip average': round(s_xyz_avg, 3),\n",
    "            'Closest point average': round(c_xyz_avg, 3),\n",
    "            'Error norm average': round(norm_avg, 3)\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
